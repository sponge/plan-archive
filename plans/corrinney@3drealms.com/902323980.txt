*** Ion Storm's Finger Server

User name: corrinne
Plan modified: Wed Aug 05 10:36:16 1998

08/05/98
BZ : I have a lunch box. Mail or call me.

06/26/98
Birthday Thoughts

"Much in the same way that no man will ever top Isaac Newton's contributions to physics, Carmack will always remain way ahead in his total contribution to the gaming field, having invented the first-person shooter genre, the multiplayer model for gaming we know today, and much more." -- Tim Sweeney 

"The Unreal engine has raised the bar on what action gamers expect from future products. The visual effects first seen in the game will become expected from future games." -- John Carmack

This is how I feel about John Carmack and the Unreal Engine. I do not have any words of my own to add.

Sometimes we graphics coders feel like artisans next to such creators. Sometimes such innovators elevate our daily routine of completing titles into pursuits of truth and beauty.

It is both exhilirating and frightening to devote your life to the pursuit of better graphics technology.

Once the passion starts, there is no turning back. There is nothing for me that challenges and titillates the senses as much as graphics coding.

06/09/98
Thanks to all the magazines for nominating us Anachronox for E3 Best of Show for Best RPG and Most Promising New Game.
http://www.e3.net/1998/award/
I do not even remember showing Anachronox to that many journalists.
Goodness. A lot of the things we were showing were so "in progress." I do hope you all would come back and see it again when we are done.
Congratulations to all the fellow nominees for a strong E3 showing.
Congratulations to Terminal Reality, 3DRealms, Ritual, Interplay, Sierra, and others.
Thanks and appreciation to my fellow Anachronoids, and my fellow ION Stormtroopers and my publisher Eidos Interactive's many little helpers for chipping in and helping out in big and little ways.
Lots of work ahead of us.

05/24/98
Congratulations to Unreal for surpassing everyone's expectations, as high as they are.

05/20/98
Bump Mapping

I put in bump mapping yesterday into my mish mash of Quake 2 refresh, it looked very tile-y and lump-y.
Consider that I am the "artiste" drawing the bump map in Photoshop, that may have something to do with it. :)

It appears there is an "art" to drawing bump maps that "work." There probably is not enough time in the next couple of days before E3 for real artists to paint or render the bumps.

Anybody out there who are better bump mapping mavens who make bumps that don't look tile-y, would be glad to hear from you on how to remove tile-i-ness.

05/12/98
Lighting

Now that I am doing more lighting work, there is something on consoles that I would really like to see on PC acclerators : color modulation saturating or maximizing to white or to a color "instead" of to original texture value.

It will be nice to maybe have an OpenGL state for GL_MODULATE_TO_TEXTURE_COLOR and GL_MODULATE_TO_COLOR. Modulating to an arbitrary color may be "hard." But what about just modulating to white only at least?

It would be interesting to hear input from IHV of the feasibility of this.
 
04/28/98
I just love volumetric. Not only does it look and feel more real, more 3 dimensional, less polygon-y, less repetitive-til-ey-canned. It is cheap, cheap, cheap. No or very little texture, upload or throughput just a few verts.

Entirely feasible in sofware. Just need the bit depth and levels of translucency, which is RAM anyway, which you have plenty of.

Yes, there is the slow fill, Carmack. But if I can keep optimize and minimize the number of polys ... But you do not have to worry about that you lucky person. :)

There are times I wish I could completely get rid of textures, then someone like skin/texture artist extraordinare Kenneth Scott comes around to render justify the existence of all skins and all textures. :)

The new engine features to Anachronox may not be Anachronox only by E3. That could be cool.

04/22/98
I have added a few new Aidoru engine features to Anachronox which will be shown in a by-invite only room at Eidos's booth at E3. For those of you who wants to see, you are most likely invited anyway, I have a few things you may like. Working on more engine features.

04/02/98
3D HW Texture Question for IHV

I understand Direct X is supporting the S3 licensed texture compression scheme. But I am just thinking, what is wrong with HW JPEG texture decompression?

1. JPEG compresses on the average of at least 5:1. On a 8 Meg card, there is now an equivalent of 40 Megs (Wow) on-board. Do not even seduce me with a 16 Meg (80 Meg, oh baby). :) Who needs AGP?
2. JPEG is already an externally documented graphics format for developers. And there are already ample graphics tools supporting that format.
3. JPEG HW decompression chip technology itself is feasible. I have seen JPEG decompression HW for 2D already.
4. Texture image quality can be "controlled" by JPEG compression ratio.
5. The bus (even the AGP, but especially the contentious PCI) will be so happy.
6. The "JPEG decompressing time" is "irrelevant" if we can parallel the bus. Please read below.

This is how we can build it on board to parallel it:
1. Have a dedicated JPEG decompression chip with a dedicated "bus" from the compressed texture RAM and to uncompressed texture RAM.
2. Have a JPEG decompression fast on-chip RAM cache of 256 x 256 ("max" texture size) for fast "writes" during decompression.
3. Texture is still referenced from "uncompressed" texture RAM, not coming out of JPEG decompression. Texturing, or texel data reading/fetching, happens in "parallel" to JPEG decompression of a different "batch" of textures. This way we do not eat up fill rate as texturing/texel data fetching is "stalled" by JPEG decompression chip.

This is how we can extend OpenGL and Direct3D to "best" support an "open" JPEG HW texture compression format:
1. OpenGL hints of texture priority can be used to affect JPEG compression/decompression queuing.
2. OpenGL extension to directly "control" which textures get JPEG-decompressed where when, if OpenGL is inclined to become "pixel" specific. With the multi-texture extension, it is already entering into that sinful world. So may as well.
3. Direct3D, since it has no qualms of changing completely :), can add DirectDraw DirectTexture interface to directly control whether the texture is going to be JPEG decompressed when.

And then developers around the world all of a sudden have lots of on-board texture RAM.

For the high-minded 3D developers (researchers) who do not want to muck with the dirty nitty-gritty texture management ... urr ... you may eat it with or without HW compression since generic texture caching schemes are seldom data and application specific. Texture management is fun. Really. It is like geometry management, except in techni-color.

These ideas just pop into my head as I am currently coding something a little mind-numbing for E3. So my thoughts are bound to be filled (fill-bound? :) ) with silly things. Just warning ya. :) Even then, responses very welcome.

03-05-98
Is there a madman with a brain
To turn the stuff of nightmares sane
And demons crush and Chaos tame,
Who'll leave his realm, forsake his bride
And, tossed by contradictory tides,
Give up his pride for pain?

May you always venture the path unblazed, madman.

02-26-98
You know those cheap little microwaveable ravioli snacks that takes TIME to go to the supermarket to purchase?
That the point of having the snacks in my cube is so I can stop being blackmailed into "going out" to have dinner or my fellow cruel programmers will starve me?
That if they will just have food "magically appear" on my desk instead of dragging my ass out to eat, that I will be less stingy of my ravioli?
;p Just kidding. You guys did bring me dinner from TLC tonight. Thanks and please do it often. Then maybe I will update tasks completed more often. 

02-22-98
My 02-18-98 .plan can be read as if I am bagging free dual-source texturing. Oops. I would have never wanted that.
I LOVE free dual-source texturing. I just want to use it for a lot more better things than perspective correct lighting. I want to save my processor from mixing in "some" light. And not all lights, like spot and specular, I do not mind "drawing" them as a texture for another pass in myself.
Come to think of it, give me free dual- ... tri- ... quad-texturing. I CAN use as many passes as you can give me for free. :)

02-22-98
I have been getting a lot of really wonderful technical email both from people I do not know, and people I know from before. I have not responded to a lot of them because most of them are just too fascinating for me to give a haphazard answer.
I guess what I am trying to say is:
1. Thank you for the great mail.
2. If I have not answered yours yet, it does NOT mean:
   a. the content of your mail is not fascinating enough to answer (oh, far from it)
   b. I do not want to continue receiving the really cool questions that you are posing
   c. I do not or have not read your cool mail because I am too busy for such things
3. It does mean:
   a. I am programming way too slowly to get enough Quake 2 "stuff" done for Daikatana and Anachronox. I am trying to work more by delaying answering a lot of my mail. I cannot wait to get all my Q2 "stuff" done so I can stop working on Aidoru part-time on the weekends.
   b. Please keep sending your cool technical comments and questions.
   c. I probably WILL reply to them with ridiculously slow turnaround.
For example, Bryan McNett asked some great displacement map questions on 01/18 and I did not answer that one until 1 month later. Sorry, Bryan.
So, please do not stop writing and sending those comments in, despite my not e-mailing much. They really make my day.

02-18-98
There is hardware support of full-screen anti-aliasing on certain cards, like the new PowerVR prototype, that does NOT have a complete 4x to 16x overhead, because the intermediate oversampled screen does not spend the time to perform video pixel writes.
Non full-screen anti-aliasing on most cards looks much worse than full-screen because full-screen anti-alias modes actually depict data at 4x the resolution, and there is detail that is actually added from sampling from the ultra-hi-res intermediate.

I have a question for IHV regarding anti-aliasing.
At each rasterization destination there is an x, but also a dx, and the contribution of these dx's actually produces better error correction of undersampling than the brute-force/non-source-detail-aware method of mooging/averaging, which is what BOTH full-screen AND non-full-screen anti-aliasing currently performs.
The effect of dx error diffusion, versus oversampling and averaging, is a much sharper image than even full-screen anti-aliasing.
Any chance an IHV would implement "true" sampling error diffusion? Is this expensive to burn in silicon?

Speaking of burning in silicon, it is true that with vertex lighting versus light mapping there is the problem that the hardware implemention of color interpolant is not perspective corrected in gouraud shading, which leads to artifacting.
I have heard that it is expensive to burn silicon (all the dividends) to perspective correct color interpolant, but some low cost vendor like S3 is planning to burn perspective correct color interpolation in their next prototype boards.
I wonder how much more expensive it is.
Is it more expensive than supporting free muti-texture, as in the performance of single-source texturing is "identical" to dual-source texturing. (I have to specify this clearly because some IHV's have taken to claiming multi-texture support by having API that supports having a second source of texture, but it is actually twice as slow; which is effectly the same as the ISV texturing twice herself.)
Because this sounds expensive too.
The point is that in order to "correct" a "mathematically incorrect" implementation of color interpolation, the software developer has to store in RAM and send down twice the amount of texture in the form of light map AND pay for the extra cost of dual-source texturing. Is the combined cost (remember the texture cache RAM cost too) of all this greater than burning perspective correct color?

Perspective correct color will become more significant as all our engines leap to next level of geometry and texture complexity. It is not just a matter of clipping. As I and others move to computationally complex geometry that simplifies into the distance and vertices with RGB disappear into the gouraud-interpolated space of the new polygon, I require that fragment to remain stable at the transition point whether or not that z-spaced perspective correct vertex sits there to pin the RGB.

These are among the many basics (also gamma standardization) I would like the IHV's to spend some brain juice on before they embark on burning geometry and transformation on graphics chips. Processors currently does an excellent job of transforming, and as far as I can tell, most ISV's high level geometry representation and pipeline for our next gen engines diverge quite a bit. Let us ISV's reach a consensus of technical superiority of high level geometry representation first, if such consensus can ever be made.

Overall, I thank the IHV's for pushing the performance of polygon set up and fill rate to the point where I even dare ask such questions.

02-09-98
I went to Microsoft and spent time with a lot of good friends, like Ray Gresko from LucasArts and Herb Marselas from Intel, and saw some old (but still good looking :) ) faces like John Ratcliff, sound programming legend. I was touched by the presence of Jim Blinn, graphics legend.

I missed seeing NVDIA (ex-SGI) friends like Michael Gold. He would not stoop to soil his soles at a Direct X event. ;p But I heard his NVIDIA co-workers are impressed with his OpenGL work. Maybe he will implement and optimize glExecute3DShooter when he is done and put all of us 3D programmers out of work.

It was interesting that Blinn is researching on precision of "standard transformation" math. I myself am also noticing the "standard" way may be insufficient to proceduralize geometry.

It was electrifying to stay up all night browsing SIGGRAPH proceedings with friends. It was humorous to dance with IHV's. ( I hope that embarrassment gets me more cards. I did not see Brian Hook stooping so low. ;p ) More seriously, I was happy to have had productive and pleasant discussions with many IHV's. I have one word to summarize my greatest peeve: subpixel (and doing it right). I also had productive and pleasant discussions with the DX team.

It saddens me greatly to witness the antagonism between the IHV's and Microsoft. Let us remember we are all here to create the best experience AND installation ease to gamers, not to execute our master plot of world domination or massage our egos of technical righteousness. I think somewhere in this API war, the computer user is left in the cold when issues like driver installation is not high on the heated debate.

Readers, please do not take this statement as my or ION's position on Direct X. I am not ready to make any yet. If you must know, I am an API agnostic. I do not have proof God exists, but many believe He is OpenGL. OpenGL is an extremely well designed API, and Direct X is stealing a lot of its good ideas, but it is still not as well designed as OpenGL.

Mark Kilgard is no longer at SGI. That is slightly disturbing.

So thank you Ray and Herb for the enjoyable conversation and pleasant company. John, I will mail you the code tonight sometime. But then you owe me a portrait. :)

1-4-98
DISCLAIMER: Since ION is licensing the Q2 engine, and since we are using it in a way that may or may not be similar to Q2, anything I am doing is an attempt (and possibly wrong-headed) to assist development of ION games, which has NOTHING to do with Q2 as a shipping game or technology FOR Q2. I regret very much any thing in my .plan file is construed as a "smack down" of Q2 as a shipping game, or as technology for Q2.

Q2 is a fine game that is developed in an amazingly short amount of time. Carmack is still the KING of scanline rasterizer, and his ability to adapt quickly to any new hardware, with the combination of Hook's hardware expertise, and Cash's multiple player programming experience, makes them an impressive team of technology developer. We all look forward to Trinity.

I am new to this .plan thing. I am used to e-mail in which the audience is people I have a (technical) history and context, and I can afford to be more careless. Now I realize I have to be more careful about all the possible permutations my .plan words can be interpreted by the general public.

1-3-98
OK, better New Year's resolution: Not piss anyone off and have him fight with me.
More seriously, removed more bugs of my LOD code, now rotationally it is stable too. And wants to rewrite criteria functions with a less worse idea than what I did. 
Thank you to all of you who mailed me k00l programming questions and discussions. And for those who are appalled by how I butcher the English language with my (I will admit at a lot of times probably WRONG, you should hear me pronounce them sometimes :) ) use of programming words, please don't read my .plan and hurt yourself. ;p
To debug my LOD, I put in a thing to freeze the POV that I am LOD-ing from and allow me to roam through the frozen world so I can examine my generated little LOD'ed Alias shells in Quake. It is a barrel of geeky fun. (I am easily amused, as well as easily impressed. :) Keeps me happy.)

1-1-98
My New Year's resolution so far is as follows:
Rewrite Quake 2 geometry pipeline math operations (3x4) into symmetrical quaternion math operations, to minimize data moves and copies, flow Pentium data accesses better, and decresase multiplies and data moves inside matrix operations. Done. (Fixed some math bugs during the re-write.) (Boy was that a lot of typing.)
Rewrite Q2 dynamic object (Alias model) geometry and drawing pipeline to improve performance. Done.
Now that ticks per frame are small enough to give me room, add dynamic, silhouette-preserving, level of detail to Alias models to slow it down again. I hope to finish debugging dynamic LOD by this weekend. It is working, but I am still seeing polygons popping rotationally though not translationally. At least Q2 engine frame rate stops being Alias model complexity dependent and remains stable, which to me is a more important goal than higher average frame rate.

The LOD code is actually stand-alone enough to pull into ION's own engine Aidoru, which I can make no progress because there is so much Quake and Quake 2 engine work left for ION games in development.  Hopefully Aidoru can evolve from Q2, but I am not counting on it. :(

I am describing my Q2 work in progress in this .plan partly to encourage id programmers to program these things instead of me. I doubt this ruse would work. ;p I am worried how much my Q2 code already diverges from Q2 license, but it appears the Carmack/Hook bug fixes/optimizations are orthogonal even on a module level from mine, so I did not screw up. I downloaded the latest Q2 patch and my Q2 version is still faster, so I feel better I did not duplicate engineering work. (It is currently not that much faster again with my LOD in progress, but I am ADDING polygons for close objects for data set simulation purpose and frame rate stability, so.)

Maybe Ms. Carly Taylor can give out Carly points to Carmack and Hook for programming some Q2 stuff. I don't think anybody wants Corrinne points. :(

I am also bounded by the polygon-based nature of Q2 model animation format, which with its now higher polygon count, data cache thrash minimization is becoming a problem. After putting in polygon-based LOD into Q2, poly-based appears to be even less probable than description-based as what I would choose as a LOD solution. I would appreciate experiencial testimonials from other LODers out there.

Yes, my New Year's resolution list is actually my Christmas vacation task list summary. This way I cheat and have a better chance of meeting my own resolution. :) Happy New Year to you all.